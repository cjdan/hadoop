1.数据大小
    按顺序给出数据存储单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB。
    1Byte = 8bit  1K = 1024Byte  1MB = 1024K
    1G = 1024M  1T = 1024G       1P = 1024T
2.大数据概念
    大数据（Big Data）：指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。
    主要解决，海量数据的存储和海量数据的分析计算问题。
3.大数据特点
    Volume（大量），Velocity（高速），Variety（多样），Value（低价值密度）
4.Hadoop简述
    4.1 Hadoop是一个由Apache基金会所开发的分布式系统基础架 构；
    4.2 主要解决，海量数据的存储和海量数据的分析计算问题；
    4.3 广义上来说，Hadoop通常是指一个更广泛的概念——Hadoop生态圈。
5.Hadoop历史
    5.1 Lucene框架是Doug Cutting开创的开源软件，用Java书写代码，实现与Google类似的全文搜索功能，它提供了全文检索引擎的架构，包括完整的查询引擎和索引引擎；
    5.2 2001年年底Lucene成为Apache基金会的一个子项目；
    5.3 对于海量数据的场景，Lucene面对与Google同样的困难，存储数据困难，检索速度慢；
    5.4 学习和模仿Google解决这些问题的办法 ：微型版Nutch；
    5.5 可以说Google是Hadoop的思想之源(Google在大数据方面的三篇论文，GFS --->HDFS，Map-Reduce --->MR，BigTable --->HBase)；
    5.6 2003-2004年，Google公开了部分GFS和MapReduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了DFS和MapReduce机制，使Nutch性能飙升;
    5.7 2005年Hadoop作为Lucene的子项目Nutch的一部分正式引入Apache基金会;
    5.8 2006年3月份，Map-Reduce和Nutch Distributed File System (NDFS) 分别被纳入到Hadoop项目中，Hadoop就此正式诞生，标志着大数据时代来临;
    5.9 名字来源于Doug Cutting儿子的玩具大象。
6.Hadoop三大发行版本
    Apache Hadoop，Cloudera Hadoop，Hortonworks Hadoop
7.Hadoop的优势
    7.1 高可靠性：Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失;
    7.2 高扩展性：在集群间分配任务数据，可方便的扩展数以千计的节点;
    7.3 高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度;
    7.4 高容错性：能够自动将失败的任务重新分配。
8.HDFS架构概述
    8.1 NameNode（nn）：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等;
    8.2 DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和;
    8.3 Secondary NameNode(2nn)：每隔一段时间对NameNode元数据备份。
9.MapReduce架构概述
    MapReduce将计算过程分为两个阶段：Map和Reduce
    9.1 Map阶段并行处理输入数据；
    9.2 Reduce阶段对Map结果进行汇总。
10.环境搭建
    配置文件包括core-site.xml，hdfs-site.xml，yarn-site.xml，mapred-site.xml
    core-site.xml:配置Common组件的属性,包括HadoopMaster的URI和端口，NameNode备份的备份间隔时间等；
    hdfs-site.xml：配置HDFS组件的属性，定义集群名字，NameNode端口，SecondNameNode配置等；
    yarn-site.xml：配置资源调度的组建，比如CPU个数，单个容器可申请的最小与最大内存，每个节点可用的最大内存等
    mapred-site.xml：配置map-reduce组件的属性，配置历史日志，map,reduce运算等...
11.HDFS写数据流程
    1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在；
    2）NameNode返回是否可以上传；
    3）客户端请求第一个 Block上传到哪几个DataNode服务器上；
    4）NameNode返回3个DataNode节点，分别为dn1、dn2、dn3；
    5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成；
    6）dn1、dn2、dn3逐级应答客户端；
    7）客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答；
    8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。
12.HDFS读数据流程
    1）客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址；
    2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据；
    3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）；
    4）客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。


















